# Distributed Medical LLM System

This project implements a **Distributed Medical Language Model (LLM)** system using a client-server architecture. The goal is to perform real-time training and inference on medical question-answering tasks by distributing the workload across multiple machines. Each client node runs a real transformer model, coordinated centrally by a server.

---

## ğŸš€ Project Overview

The system leverages distributed computing to train and run a medical Q&A model across multiple machines using **ZeroMQ** for communication. It is designed to demonstrate how real transformer-based LLMs can be fine-tuned and queried in a distributed setup.

- ğŸ§  **Model Used**: `distilbert-base-uncased`
- ğŸ–¥ï¸ **Distributed Setup**:
  - 1 Server (controller)
  - 6 Clients (workers)
- ğŸ”— **Communication Protocol**: ZeroMQ
- ğŸ’¬ **Frontend**: HTML-based dashboard for control & visualization
- ğŸ“š **Dataset**: Preloaded Q&A pairs for training (can be extended)

---

## ğŸ§± Architecture

```bash
ğŸ“¡ Server
 â”œâ”€â”€ Sends setup, training, and inference commands
 â”œâ”€â”€ Receives results from all clients
 â””â”€â”€ Displays logs & status updates

ğŸ§  Clients (x6)
 â”œâ”€â”€ Load transformer model
 â”œâ”€â”€ Fine-tune on provided medical data
 â”œâ”€â”€ Respond to inference queries
```

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ client.py           # Real training + inference client
â”œâ”€â”€ server.py           # Main controller to manage all clients
â”œâ”€â”€ test.py             # Utility to send a test inference to a client
â”œâ”€â”€ index.html          # Dashboard UI
â”œâ”€â”€ server_debug.log    # Sample log file from the server
â”œâ”€â”€ README.md           # This file
```

---

## ğŸ”§ Technologies Used

- **Python 3**
- **HuggingFace Transformers** (`distilbert-base-uncased`)
- **Datasets** (for Q&A)
- **PyTorch**
- **ZeroMQ** (for messaging)
- **HTML/CSS/JS** (UI dashboard)

---

## ğŸ’¬ Sample Questions Supported

```text
- What is diabetes?
- What are the symptoms of a heart attack?
- How does the COVID-19 vaccine work?
- What causes high blood pressure?
- What is Alzheimerâ€™s disease?
```

---

## ğŸ¯ Features

- âœ… Distributed transformer model training
- âœ… Real-time inference from multiple nodes
- âœ… ZeroMQ-based message passing
- âœ… Dashboard for question input and logs
- âœ… Logging and test utilities

---

## ğŸ› ï¸ How to Run

### 1. Install Requirements
```bash
pip install transformers datasets torch pyzmq
```

### 2. Start Clients (on each of the 6 client machines)
```bash
python client.py --port 5555 --server_ip <server-ip>
```

### 3. Start Server
```bash
python server.py --client_ips 192.168.1.101 192.168.1.102 ...
```

### 4. Launch Dashboard
Just open `index.html` in your browser to interact with the system.

### 5. Run Test
```bash
python test.py --client <client-ip> --question "What is diabetes?"
```

---

## ğŸ“· Screenshot

![Dashboard](screenshots/dashboard.png)

---

## ğŸ› Known Issues

- If `bitsandbytes` isn't installed, quantized model loading may fail (not needed for distilbert).
- Some clients may not connect if network config is incorrect.
- Inference must be triggered after all clients are marked ready.

---

## ğŸ“Œ Future Enhancements

- Web API layer for frontend-backend connection
- Docker containers for easier deployment
- Advanced model options (e.g., Mistral, LLaMA)
- Automatic data sharding across clients

---

## ğŸ‘¨â€ğŸ’» Contributors

- **Lead Developer**: [Your Name Here]
- **Team**: [Add team members if applicable]

---

## ğŸ“„ License

This project is licensed under the MIT License. Feel free to use, adapt, and contribute!
